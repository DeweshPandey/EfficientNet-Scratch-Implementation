{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqdG2dAdx9iP"
      },
      "outputs": [],
      "source": [
        "# In the efficientNet the idea is not to give a new architechture but to modify the baseline model by scaling method called Compound Scaling Method\n",
        "# This is done by scaling the depth (number of layers), width ( number of channels), resolution of image by some factore alpha^phi , beta^phi , gamma^phi\n",
        "# where alpha*(beta^2)*(gamma^2) = 2 ( nearly equal to) and alpha, beta, gamma >= 1 as constraints\n",
        "# alpha, beta , gamma are constant determined by grid search over constraints\n",
        "# various techniques is used for these which include : mobile inverted resdual layer, squeeze and excitation optimization, stochastic depth  , survival prob, moble net depth wise convolution\n",
        "# A little bit complex model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OgYt3MpisQJ-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from math import ceil\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1j0lu6PtzeYx"
      },
      "outputs": [],
      "source": [
        "# with reference to the EfficientNet Paper\n",
        "base_model = [\n",
        "    # [expand_ratio, channels, repeats, stride, kernel_size]\n",
        "    [1, 16, 1, 1, 3 ],\n",
        "    [6, 24, 2, 2, 3],\n",
        "    [6, 40, 2, 2, 5],\n",
        "    [6, 80, 3, 2, 3],\n",
        "    [6, 112, 3, 1, 5],\n",
        "    [6, 192, 4, 2, 5],\n",
        "    [6, 320, 1, 1, 3],\n",
        "]\n",
        "\n",
        "phi_values ={\n",
        "    # tuple of : ( phi_value, resolution, drop_rate)\n",
        "    \"b0\": (0, 224, 0.2), # alpha, beta, gamma, depth = alpha**phi\n",
        "    \"b1\": (0.5, 240 , 0.2),\n",
        "    \"b2\": (1, 260, 0.3),\n",
        "    \"b3\": (2, 300, 0.3),\n",
        "    \"b4\": (3, 380, 0.4),\n",
        "    \"b5\": (4, 456, 0.4),\n",
        "    \"b6\": (5, 528, 0.5),\n",
        "    \"b7\": (6, 600, 0.5),\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yLtBL7vA1nwC"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding , groups = 1):\n",
        "\n",
        "    super(CNNBlock, self).__init__()\n",
        "    self.cnn = nn.Conv2d( in_channels, out_channels, kernel_size, stride, padding, groups= groups, bias = False) # groups for depth-wise-convolution\n",
        "    # if groups = 1  then it is normal convolution\n",
        "    # if groups = in_channels then it is Depthwise convolution\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.silu = nn.SiLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.silu(self.bn(self.cnn(x)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "P7qTSrfg1tkX"
      },
      "outputs": [],
      "source": [
        "class SqueezeExcitation(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, reduced_dim):\n",
        "\n",
        "    super(SqueezeExcitation, self).__init__()\n",
        "    self.se = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1), # C x H x W -> C x1 x1\n",
        "        nn.Conv2d( in_channels, reduced_dim , 1),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d( reduced_dim, in_channels, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x*self.se(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bO8hiAOx1yyB"
      },
      "outputs": [],
      "source": [
        "class InvertedResidualBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding , expand_ratio, reduction =4, survival_prob = 0.8): # expand_ration uses depthwise convoluton to expand to higher no. of channels and then reduce it to initial no. of channels\n",
        "    # reduction is for reduced_di for SqueezeExcitaion\n",
        "    # for stochastic depth is survival_prob\n",
        "    super(InvertedResidualBlock, self).__init__()\n",
        "\n",
        "    self.survival_prob = 0.8\n",
        "    self.use_residual = in_channels == out_channels and stride == 1 # i.e. skip connections can only be used when input and output channels match\n",
        "    hidden_dim = in_channels*expand_ratio\n",
        "    self.expand = in_channels != hidden_dim\n",
        "    reduced_dim = in_channels //reduction\n",
        "\n",
        "    if self.expand:\n",
        "      self.expand_conv = CNNBlock( in_channels, hidden_dim , kernel_size =3, stride = 1, padding =1)\n",
        "\n",
        "    self.conv = nn.Sequential(\n",
        "        CNNBlock( hidden_dim, hidden_dim, kernel_size, stride, padding, groups = hidden_dim),\n",
        "        SqueezeExcitation(hidden_dim, reduced_dim),\n",
        "        nn.Conv2d(hidden_dim, out_channels, 1, bias= False ) , # bottle neck convolution to change number of channels\n",
        "        nn.BatchNorm2d( out_channels),\n",
        "    )\n",
        "\n",
        "  def stochastic_depth(self, x):\n",
        "    if not self.training:\n",
        "      return x\n",
        "\n",
        "    binary_tenosr = torch.rand(x.shape[0], 1,1,1 , device = x.device ) < self.survival_prob\n",
        "    return torch.div(x, self.survival_prob)*binary_tenosr\n",
        "\n",
        "  def forward(self, input ):\n",
        "\n",
        "    x = self.expand_conv(input ) if self.expand else input\n",
        "\n",
        "    if self.use_residual:\n",
        "      return self.stochastic_depth(self.conv(x)) + input # this is the residual connection adding input\n",
        "\n",
        "    else:\n",
        "      return self.conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dGi7Qoc914hc"
      },
      "outputs": [],
      "source": [
        "class EfficientNet(nn.Module):\n",
        "\n",
        "  def __init__(self, version, num_classes):\n",
        "\n",
        "    super(EfficientNet, self).__init__()\n",
        "    width_factor, depth_factor, dropout_rate = self.calculate_factors(version)\n",
        "    last_channels = ceil(1280*width_factor)\n",
        "    self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "    self.features = self.create_features(width_factor, depth_factor, last_channels)\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(dropout_rate),\n",
        "        nn.Linear(last_channels, num_classes)\n",
        "    )\n",
        "\n",
        "  def calculate_factors(self, version, alpha = 1.2, beta = 1.1  ):\n",
        "    phi, res, drop_rate = phi_values[version]\n",
        "    depth_factor, width_factor = alpha**phi, beta**phi\n",
        "    return width_factor, depth_factor, drop_rate\n",
        "\n",
        "\n",
        "  def create_features(self, width_factor, depth_factor, last_channels):\n",
        "    channels = int(32*width_factor)\n",
        "    features = [CNNBlock(3, channels, 3, stride =2 , padding= 1)] # this list will contain whole architechture  and passed to Sequential(#features)\n",
        "    in_channels = channels\n",
        "\n",
        "    for expand_ratio , channels, num_repeats, stride, kernel_size in base_model:\n",
        "      out_channels = 4*ceil(int(channels*width_factor)/4)\n",
        "      layer_repeats = ceil(num_repeats*depth_factor)\n",
        "\n",
        "      for layer in range(layer_repeats):\n",
        "        features.append(\n",
        "            InvertedResidualBlock(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                expand_ratio = expand_ratio,\n",
        "                stride = stride if layer ==0 else 1,  # we want to downsample at start of each block\n",
        "                kernel_size = kernel_size,\n",
        "                padding = kernel_size//2 , # if kernel = 1, pad = 0 , kernel =3 pad =1 ... an so on to maintain the size of\n",
        "\n",
        "            )\n",
        "        )\n",
        "        in_channels = out_channels\n",
        "\n",
        "    features.append(\n",
        "            CNNBlock(in_channels, last_channels, kernel_size =1 , stride = 1, padding =0)\n",
        "        )\n",
        "\n",
        "    return nn.Sequential(*features)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(self.features(x))\n",
        "    return self.classifier(x.view(x.shape[0], -1))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vVUtzNdEK2D1"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  version = \"b0\"\n",
        "  phi , res, drop_rate = phi_values[version]\n",
        "  num_examples, num_classes = 4, 10\n",
        "  x = torch.rand((num_examples, 3, res, res)).to(device)\n",
        "  model = EfficientNet(\n",
        "      version = version,\n",
        "      num_classes = num_classes\n",
        "  ).to(device)\n",
        "\n",
        "  print(model(x).shape) # (num_examples, num_classes)\n",
        "  print(summary(model=model, input_size=(3, 224, 224), device=\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CCeeF13LdH6",
        "outputId": "f15e3e32-3102-49d6-e503-d4dc707a9c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 10])\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "              SiLU-3         [-1, 32, 112, 112]               0\n",
            "          CNNBlock-4         [-1, 32, 112, 112]               0\n",
            "            Conv2d-5         [-1, 32, 112, 112]             288\n",
            "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
            "              SiLU-7         [-1, 32, 112, 112]               0\n",
            "          CNNBlock-8         [-1, 32, 112, 112]               0\n",
            " AdaptiveAvgPool2d-9             [-1, 32, 1, 1]               0\n",
            "           Conv2d-10              [-1, 8, 1, 1]             264\n",
            "             SiLU-11              [-1, 8, 1, 1]               0\n",
            "           Conv2d-12             [-1, 32, 1, 1]             288\n",
            "          Sigmoid-13             [-1, 32, 1, 1]               0\n",
            "SqueezeExcitation-14         [-1, 32, 112, 112]               0\n",
            "           Conv2d-15         [-1, 16, 112, 112]             512\n",
            "      BatchNorm2d-16         [-1, 16, 112, 112]              32\n",
            "InvertedResidualBlock-17         [-1, 16, 112, 112]               0\n",
            "           Conv2d-18         [-1, 96, 112, 112]          13,824\n",
            "      BatchNorm2d-19         [-1, 96, 112, 112]             192\n",
            "             SiLU-20         [-1, 96, 112, 112]               0\n",
            "         CNNBlock-21         [-1, 96, 112, 112]               0\n",
            "           Conv2d-22           [-1, 96, 56, 56]             864\n",
            "      BatchNorm2d-23           [-1, 96, 56, 56]             192\n",
            "             SiLU-24           [-1, 96, 56, 56]               0\n",
            "         CNNBlock-25           [-1, 96, 56, 56]               0\n",
            "AdaptiveAvgPool2d-26             [-1, 96, 1, 1]               0\n",
            "           Conv2d-27              [-1, 4, 1, 1]             388\n",
            "             SiLU-28              [-1, 4, 1, 1]               0\n",
            "           Conv2d-29             [-1, 96, 1, 1]             480\n",
            "          Sigmoid-30             [-1, 96, 1, 1]               0\n",
            "SqueezeExcitation-31           [-1, 96, 56, 56]               0\n",
            "           Conv2d-32           [-1, 24, 56, 56]           2,304\n",
            "      BatchNorm2d-33           [-1, 24, 56, 56]              48\n",
            "InvertedResidualBlock-34           [-1, 24, 56, 56]               0\n",
            "           Conv2d-35          [-1, 144, 56, 56]          31,104\n",
            "      BatchNorm2d-36          [-1, 144, 56, 56]             288\n",
            "             SiLU-37          [-1, 144, 56, 56]               0\n",
            "         CNNBlock-38          [-1, 144, 56, 56]               0\n",
            "           Conv2d-39          [-1, 144, 56, 56]           1,296\n",
            "      BatchNorm2d-40          [-1, 144, 56, 56]             288\n",
            "             SiLU-41          [-1, 144, 56, 56]               0\n",
            "         CNNBlock-42          [-1, 144, 56, 56]               0\n",
            "AdaptiveAvgPool2d-43            [-1, 144, 1, 1]               0\n",
            "           Conv2d-44              [-1, 6, 1, 1]             870\n",
            "             SiLU-45              [-1, 6, 1, 1]               0\n",
            "           Conv2d-46            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-47            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-48          [-1, 144, 56, 56]               0\n",
            "           Conv2d-49           [-1, 24, 56, 56]           3,456\n",
            "      BatchNorm2d-50           [-1, 24, 56, 56]              48\n",
            "InvertedResidualBlock-51           [-1, 24, 56, 56]               0\n",
            "           Conv2d-52          [-1, 144, 56, 56]          31,104\n",
            "      BatchNorm2d-53          [-1, 144, 56, 56]             288\n",
            "             SiLU-54          [-1, 144, 56, 56]               0\n",
            "         CNNBlock-55          [-1, 144, 56, 56]               0\n",
            "           Conv2d-56          [-1, 144, 28, 28]           3,600\n",
            "      BatchNorm2d-57          [-1, 144, 28, 28]             288\n",
            "             SiLU-58          [-1, 144, 28, 28]               0\n",
            "         CNNBlock-59          [-1, 144, 28, 28]               0\n",
            "AdaptiveAvgPool2d-60            [-1, 144, 1, 1]               0\n",
            "           Conv2d-61              [-1, 6, 1, 1]             870\n",
            "             SiLU-62              [-1, 6, 1, 1]               0\n",
            "           Conv2d-63            [-1, 144, 1, 1]           1,008\n",
            "          Sigmoid-64            [-1, 144, 1, 1]               0\n",
            "SqueezeExcitation-65          [-1, 144, 28, 28]               0\n",
            "           Conv2d-66           [-1, 40, 28, 28]           5,760\n",
            "      BatchNorm2d-67           [-1, 40, 28, 28]              80\n",
            "InvertedResidualBlock-68           [-1, 40, 28, 28]               0\n",
            "           Conv2d-69          [-1, 240, 28, 28]          86,400\n",
            "      BatchNorm2d-70          [-1, 240, 28, 28]             480\n",
            "             SiLU-71          [-1, 240, 28, 28]               0\n",
            "         CNNBlock-72          [-1, 240, 28, 28]               0\n",
            "           Conv2d-73          [-1, 240, 28, 28]           6,000\n",
            "      BatchNorm2d-74          [-1, 240, 28, 28]             480\n",
            "             SiLU-75          [-1, 240, 28, 28]               0\n",
            "         CNNBlock-76          [-1, 240, 28, 28]               0\n",
            "AdaptiveAvgPool2d-77            [-1, 240, 1, 1]               0\n",
            "           Conv2d-78             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-79             [-1, 10, 1, 1]               0\n",
            "           Conv2d-80            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-81            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-82          [-1, 240, 28, 28]               0\n",
            "           Conv2d-83           [-1, 40, 28, 28]           9,600\n",
            "      BatchNorm2d-84           [-1, 40, 28, 28]              80\n",
            "InvertedResidualBlock-85           [-1, 40, 28, 28]               0\n",
            "           Conv2d-86          [-1, 240, 28, 28]          86,400\n",
            "      BatchNorm2d-87          [-1, 240, 28, 28]             480\n",
            "             SiLU-88          [-1, 240, 28, 28]               0\n",
            "         CNNBlock-89          [-1, 240, 28, 28]               0\n",
            "           Conv2d-90          [-1, 240, 14, 14]           2,160\n",
            "      BatchNorm2d-91          [-1, 240, 14, 14]             480\n",
            "             SiLU-92          [-1, 240, 14, 14]               0\n",
            "         CNNBlock-93          [-1, 240, 14, 14]               0\n",
            "AdaptiveAvgPool2d-94            [-1, 240, 1, 1]               0\n",
            "           Conv2d-95             [-1, 10, 1, 1]           2,410\n",
            "             SiLU-96             [-1, 10, 1, 1]               0\n",
            "           Conv2d-97            [-1, 240, 1, 1]           2,640\n",
            "          Sigmoid-98            [-1, 240, 1, 1]               0\n",
            "SqueezeExcitation-99          [-1, 240, 14, 14]               0\n",
            "          Conv2d-100           [-1, 80, 14, 14]          19,200\n",
            "     BatchNorm2d-101           [-1, 80, 14, 14]             160\n",
            "InvertedResidualBlock-102           [-1, 80, 14, 14]               0\n",
            "          Conv2d-103          [-1, 480, 14, 14]         345,600\n",
            "     BatchNorm2d-104          [-1, 480, 14, 14]             960\n",
            "            SiLU-105          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-106          [-1, 480, 14, 14]               0\n",
            "          Conv2d-107          [-1, 480, 14, 14]           4,320\n",
            "     BatchNorm2d-108          [-1, 480, 14, 14]             960\n",
            "            SiLU-109          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-110          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-111            [-1, 480, 1, 1]               0\n",
            "          Conv2d-112             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-113             [-1, 20, 1, 1]               0\n",
            "          Conv2d-114            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-115            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-116          [-1, 480, 14, 14]               0\n",
            "          Conv2d-117           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-118           [-1, 80, 14, 14]             160\n",
            "InvertedResidualBlock-119           [-1, 80, 14, 14]               0\n",
            "          Conv2d-120          [-1, 480, 14, 14]         345,600\n",
            "     BatchNorm2d-121          [-1, 480, 14, 14]             960\n",
            "            SiLU-122          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-123          [-1, 480, 14, 14]               0\n",
            "          Conv2d-124          [-1, 480, 14, 14]           4,320\n",
            "     BatchNorm2d-125          [-1, 480, 14, 14]             960\n",
            "            SiLU-126          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-127          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-128            [-1, 480, 1, 1]               0\n",
            "          Conv2d-129             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-130             [-1, 20, 1, 1]               0\n",
            "          Conv2d-131            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-132            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-133          [-1, 480, 14, 14]               0\n",
            "          Conv2d-134           [-1, 80, 14, 14]          38,400\n",
            "     BatchNorm2d-135           [-1, 80, 14, 14]             160\n",
            "InvertedResidualBlock-136           [-1, 80, 14, 14]               0\n",
            "          Conv2d-137          [-1, 480, 14, 14]         345,600\n",
            "     BatchNorm2d-138          [-1, 480, 14, 14]             960\n",
            "            SiLU-139          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-140          [-1, 480, 14, 14]               0\n",
            "          Conv2d-141          [-1, 480, 14, 14]          12,000\n",
            "     BatchNorm2d-142          [-1, 480, 14, 14]             960\n",
            "            SiLU-143          [-1, 480, 14, 14]               0\n",
            "        CNNBlock-144          [-1, 480, 14, 14]               0\n",
            "AdaptiveAvgPool2d-145            [-1, 480, 1, 1]               0\n",
            "          Conv2d-146             [-1, 20, 1, 1]           9,620\n",
            "            SiLU-147             [-1, 20, 1, 1]               0\n",
            "          Conv2d-148            [-1, 480, 1, 1]          10,080\n",
            "         Sigmoid-149            [-1, 480, 1, 1]               0\n",
            "SqueezeExcitation-150          [-1, 480, 14, 14]               0\n",
            "          Conv2d-151          [-1, 112, 14, 14]          53,760\n",
            "     BatchNorm2d-152          [-1, 112, 14, 14]             224\n",
            "InvertedResidualBlock-153          [-1, 112, 14, 14]               0\n",
            "          Conv2d-154          [-1, 672, 14, 14]         677,376\n",
            "     BatchNorm2d-155          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-156          [-1, 672, 14, 14]               0\n",
            "        CNNBlock-157          [-1, 672, 14, 14]               0\n",
            "          Conv2d-158          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-159          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-160          [-1, 672, 14, 14]               0\n",
            "        CNNBlock-161          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
            "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-164             [-1, 28, 1, 1]               0\n",
            "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
            "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
            "InvertedResidualBlock-170          [-1, 112, 14, 14]               0\n",
            "          Conv2d-171          [-1, 672, 14, 14]         677,376\n",
            "     BatchNorm2d-172          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-173          [-1, 672, 14, 14]               0\n",
            "        CNNBlock-174          [-1, 672, 14, 14]               0\n",
            "          Conv2d-175          [-1, 672, 14, 14]          16,800\n",
            "     BatchNorm2d-176          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-177          [-1, 672, 14, 14]               0\n",
            "        CNNBlock-178          [-1, 672, 14, 14]               0\n",
            "AdaptiveAvgPool2d-179            [-1, 672, 1, 1]               0\n",
            "          Conv2d-180             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-181             [-1, 28, 1, 1]               0\n",
            "          Conv2d-182            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-183            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-184          [-1, 672, 14, 14]               0\n",
            "          Conv2d-185          [-1, 112, 14, 14]          75,264\n",
            "     BatchNorm2d-186          [-1, 112, 14, 14]             224\n",
            "InvertedResidualBlock-187          [-1, 112, 14, 14]               0\n",
            "          Conv2d-188          [-1, 672, 14, 14]         677,376\n",
            "     BatchNorm2d-189          [-1, 672, 14, 14]           1,344\n",
            "            SiLU-190          [-1, 672, 14, 14]               0\n",
            "        CNNBlock-191          [-1, 672, 14, 14]               0\n",
            "          Conv2d-192            [-1, 672, 7, 7]          16,800\n",
            "     BatchNorm2d-193            [-1, 672, 7, 7]           1,344\n",
            "            SiLU-194            [-1, 672, 7, 7]               0\n",
            "        CNNBlock-195            [-1, 672, 7, 7]               0\n",
            "AdaptiveAvgPool2d-196            [-1, 672, 1, 1]               0\n",
            "          Conv2d-197             [-1, 28, 1, 1]          18,844\n",
            "            SiLU-198             [-1, 28, 1, 1]               0\n",
            "          Conv2d-199            [-1, 672, 1, 1]          19,488\n",
            "         Sigmoid-200            [-1, 672, 1, 1]               0\n",
            "SqueezeExcitation-201            [-1, 672, 7, 7]               0\n",
            "          Conv2d-202            [-1, 192, 7, 7]         129,024\n",
            "     BatchNorm2d-203            [-1, 192, 7, 7]             384\n",
            "InvertedResidualBlock-204            [-1, 192, 7, 7]               0\n",
            "          Conv2d-205           [-1, 1152, 7, 7]       1,990,656\n",
            "     BatchNorm2d-206           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-207           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-208           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-209           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-210           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-211           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-212           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-213           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-214             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-215             [-1, 48, 1, 1]               0\n",
            "          Conv2d-216           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-217           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-218           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-219            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-220            [-1, 192, 7, 7]             384\n",
            "InvertedResidualBlock-221            [-1, 192, 7, 7]               0\n",
            "          Conv2d-222           [-1, 1152, 7, 7]       1,990,656\n",
            "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-224           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-225           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-226           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-227           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-228           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-229           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-230           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-231             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-232             [-1, 48, 1, 1]               0\n",
            "          Conv2d-233           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-234           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-235           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-236            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-237            [-1, 192, 7, 7]             384\n",
            "InvertedResidualBlock-238            [-1, 192, 7, 7]               0\n",
            "          Conv2d-239           [-1, 1152, 7, 7]       1,990,656\n",
            "     BatchNorm2d-240           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-241           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-242           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-243           [-1, 1152, 7, 7]          28,800\n",
            "     BatchNorm2d-244           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-245           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-246           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-247           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-248             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-249             [-1, 48, 1, 1]               0\n",
            "          Conv2d-250           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-251           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-252           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-253            [-1, 192, 7, 7]         221,184\n",
            "     BatchNorm2d-254            [-1, 192, 7, 7]             384\n",
            "InvertedResidualBlock-255            [-1, 192, 7, 7]               0\n",
            "          Conv2d-256           [-1, 1152, 7, 7]       1,990,656\n",
            "     BatchNorm2d-257           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-258           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-259           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-260           [-1, 1152, 7, 7]          10,368\n",
            "     BatchNorm2d-261           [-1, 1152, 7, 7]           2,304\n",
            "            SiLU-262           [-1, 1152, 7, 7]               0\n",
            "        CNNBlock-263           [-1, 1152, 7, 7]               0\n",
            "AdaptiveAvgPool2d-264           [-1, 1152, 1, 1]               0\n",
            "          Conv2d-265             [-1, 48, 1, 1]          55,344\n",
            "            SiLU-266             [-1, 48, 1, 1]               0\n",
            "          Conv2d-267           [-1, 1152, 1, 1]          56,448\n",
            "         Sigmoid-268           [-1, 1152, 1, 1]               0\n",
            "SqueezeExcitation-269           [-1, 1152, 7, 7]               0\n",
            "          Conv2d-270            [-1, 320, 7, 7]         368,640\n",
            "     BatchNorm2d-271            [-1, 320, 7, 7]             640\n",
            "InvertedResidualBlock-272            [-1, 320, 7, 7]               0\n",
            "          Conv2d-273           [-1, 1280, 7, 7]         409,600\n",
            "     BatchNorm2d-274           [-1, 1280, 7, 7]           2,560\n",
            "            SiLU-275           [-1, 1280, 7, 7]               0\n",
            "        CNNBlock-276           [-1, 1280, 7, 7]               0\n",
            "AdaptiveAvgPool2d-277           [-1, 1280, 1, 1]               0\n",
            "         Dropout-278                 [-1, 1280]               0\n",
            "          Linear-279                   [-1, 10]          12,810\n",
            "================================================================\n",
            "Total params: 14,047,366\n",
            "Trainable params: 14,047,366\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 219.02\n",
            "Params size (MB): 53.59\n",
            "Estimated Total Size (MB): 273.18\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAyi52zcP1li"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
